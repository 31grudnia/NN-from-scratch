{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from nn_with_py.NNModels.Model import Model\n",
    "from nn_with_py.Layers.LayerDense import Layer_Dense\n",
    "from nn_with_py.Layers.LayerDropout import Layer_Dropout\n",
    "from nn_with_py.ActivationFunctions.ActivationRelu import Activation_Relu\n",
    "from nn_with_py.ActivationFunctions.ActivationSoftmax import Activation_Softmax\n",
    "from nn_with_py.LossFunctions.LossCategoricalCrossentropy import Loss_CategoricalCrossentropy\n",
    "from nn_with_py.Optimizers.OptimizerAdam import Optimizer_Adam\n",
    "from nn_with_py.Accuracy.AccuracyCategorical import Accuracy_Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/Users/mikolajstarczewski/Desktop/Magisterka/NN_with_py/nn_with_py/data_files/\"\n",
    "\n",
    "X_train = np.load(PATH + \"X_train.npy\")\n",
    "X_test = np.load(PATH + \"X_test.npy\")\n",
    "Y_train = np.load(PATH + \"Y_train.npy\")\n",
    "Y_test = np.load(PATH + \"Y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(446524, 1024)\n",
      "(1024,)\n",
      "1024\n",
      "(55815, 1024)\n",
      "(1024,)\n"
     ]
    }
   ],
   "source": [
    "# Flattening Data\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train[0].shape)\n",
    "print(32*32)\n",
    "print(X_test.shape)\n",
    "print(X_test[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model_w_py = Model()\n",
    "\n",
    "nn_model_w_py.add(Layer_Dense(X_train.shape[1], 256))\n",
    "nn_model_w_py.add(Activation_Relu())\n",
    "nn_model_w_py.add(Layer_Dense(256, 128))\n",
    "nn_model_w_py.add(Activation_Relu())\n",
    "nn_model_w_py.add(Layer_Dense(128, 128))\n",
    "nn_model_w_py.add(Activation_Relu())\n",
    "nn_model_w_py.add(Layer_Dropout(0.2))\n",
    "nn_model_w_py.add(Layer_Dense(128, 89))\n",
    "nn_model_w_py.add(Activation_Softmax())\n",
    "\n",
    "nn_model_w_py.set(\n",
    "    loss=Loss_CategoricalCrossentropy(),\n",
    "    optimizer=Optimizer_Adam(decay=1e-4),\n",
    "    accuracy=Accuracy_Categorical()\n",
    ")\n",
    "\n",
    "nn_model_w_py.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "step: 0, acc: 0.000, loss: 4.489 (data_loss: 4.489, reg_loss: 0.000), lr: 0.001\n",
      "step: 500, acc: 0.094, loss: 3.410 (data_loss: 3.410, reg_loss: 0.000), lr: 0.0009523809523809524\n",
      "step: 1000, acc: 0.172, loss: 2.936 (data_loss: 2.936, reg_loss: 0.000), lr: 0.0009090909090909091\n",
      "step: 1500, acc: 0.242, loss: 2.399 (data_loss: 2.399, reg_loss: 0.000), lr: 0.0008695652173913045\n",
      "step: 2000, acc: 0.305, loss: 2.599 (data_loss: 2.599, reg_loss: 0.000), lr: 0.0008333333333333334\n",
      "step: 2500, acc: 0.336, loss: 2.224 (data_loss: 2.224, reg_loss: 0.000), lr: 0.0008\n",
      "step: 3000, acc: 0.414, loss: 1.874 (data_loss: 1.874, reg_loss: 0.000), lr: 0.0007692307692307692\n",
      "step: 3488, acc: 0.350, loss: 1.910 (data_loss: 1.910, reg_loss: 0.000), lr: 0.000741399762752076\n",
      "training, acc: 0.267, loss: 2.671 (data_loss: 2.671, reg_loss: 0.000), lr: 0.000741399762752076\n",
      "validation, acc: 0.491, loss: 1.737\n",
      "epoch: 2\n",
      "step: 0, acc: 0.461, loss: 1.777 (data_loss: 1.777, reg_loss: 0.000), lr: 0.0007413447994662318\n",
      "step: 500, acc: 0.391, loss: 2.056 (data_loss: 2.056, reg_loss: 0.000), lr: 0.000714847380084352\n",
      "step: 1000, acc: 0.500, loss: 1.746 (data_loss: 1.746, reg_loss: 0.000), lr: 0.0006901787562978812\n",
      "step: 1500, acc: 0.547, loss: 1.532 (data_loss: 1.532, reg_loss: 0.000), lr: 0.0006671559143371807\n",
      "step: 2000, acc: 0.531, loss: 1.641 (data_loss: 1.641, reg_loss: 0.000), lr: 0.000645619471883272\n",
      "step: 2500, acc: 0.523, loss: 1.555 (data_loss: 1.555, reg_loss: 0.000), lr: 0.0006254299831133905\n",
      "step: 3000, acc: 0.539, loss: 1.383 (data_loss: 1.383, reg_loss: 0.000), lr: 0.0006064649160046092\n",
      "step: 3488, acc: 0.533, loss: 1.535 (data_loss: 1.535, reg_loss: 0.000), lr: 0.0005890322200624374\n",
      "training, acc: 0.515, loss: 1.626 (data_loss: 1.626, reg_loss: 0.000), lr: 0.0005890322200624374\n",
      "validation, acc: 0.618, loss: 1.260\n",
      "epoch: 3\n",
      "step: 0, acc: 0.672, loss: 1.208 (data_loss: 1.208, reg_loss: 0.000), lr: 0.0005889975262103899\n",
      "step: 500, acc: 0.500, loss: 1.721 (data_loss: 1.721, reg_loss: 0.000), lr: 0.0005721478430026318\n",
      "step: 1000, acc: 0.602, loss: 1.324 (data_loss: 1.324, reg_loss: 0.000), lr: 0.0005562353988207808\n",
      "step: 1500, acc: 0.602, loss: 1.292 (data_loss: 1.292, reg_loss: 0.000), lr: 0.000541184110834506\n",
      "step: 2000, acc: 0.570, loss: 1.491 (data_loss: 1.491, reg_loss: 0.000), lr: 0.0005269259142164612\n",
      "step: 2500, acc: 0.523, loss: 1.376 (data_loss: 1.376, reg_loss: 0.000), lr: 0.0005133997330321388\n",
      "step: 3000, acc: 0.688, loss: 1.136 (data_loss: 1.136, reg_loss: 0.000), lr: 0.0005005506056662329\n",
      "step: 3488, acc: 0.550, loss: 1.297 (data_loss: 1.297, reg_loss: 0.000), lr: 0.0004886152643408581\n",
      "training, acc: 0.587, loss: 1.342 (data_loss: 1.342, reg_loss: 0.000), lr: 0.0004886152643408581\n",
      "validation, acc: 0.654, loss: 1.101\n",
      "epoch: 4\n",
      "step: 0, acc: 0.656, loss: 1.150 (data_loss: 1.150, reg_loss: 0.000), lr: 0.0004885913910196903\n",
      "step: 500, acc: 0.586, loss: 1.526 (data_loss: 1.526, reg_loss: 0.000), lr: 0.00047693995325988456\n",
      "step: 1000, acc: 0.578, loss: 1.142 (data_loss: 1.142, reg_loss: 0.000), lr: 0.0004658312759118647\n",
      "step: 1500, acc: 0.672, loss: 1.065 (data_loss: 1.065, reg_loss: 0.000), lr: 0.00045522829699094097\n",
      "step: 2000, acc: 0.609, loss: 1.383 (data_loss: 1.383, reg_loss: 0.000), lr: 0.0004450972537499444\n",
      "step: 2500, acc: 0.602, loss: 1.280 (data_loss: 1.280, reg_loss: 0.000), lr: 0.0004354073235511821\n",
      "step: 3000, acc: 0.648, loss: 1.118 (data_loss: 1.118, reg_loss: 0.000), lr: 0.0004261303106489964\n",
      "step: 3488, acc: 0.650, loss: 1.268 (data_loss: 1.268, reg_loss: 0.000), lr: 0.0004174493842621582\n",
      "training, acc: 0.621, loss: 1.214 (data_loss: 1.214, reg_loss: 0.000), lr: 0.0004174493842621582\n",
      "validation, acc: 0.676, loss: 1.030\n",
      "epoch: 5\n",
      "step: 0, acc: 0.703, loss: 0.961 (data_loss: 0.961, reg_loss: 0.000), lr: 0.0004174319585907497\n",
      "step: 500, acc: 0.633, loss: 1.332 (data_loss: 1.332, reg_loss: 0.000), lr: 0.00040889761203794574\n",
      "step: 1000, acc: 0.586, loss: 1.198 (data_loss: 1.198, reg_loss: 0.000), lr: 0.0004007052412245552\n",
      "step: 1500, acc: 0.656, loss: 1.216 (data_loss: 1.216, reg_loss: 0.000), lr: 0.0003928346951602765\n",
      "step: 2000, acc: 0.602, loss: 1.258 (data_loss: 1.258, reg_loss: 0.000), lr: 0.0003852673755586377\n",
      "step: 2500, acc: 0.570, loss: 1.072 (data_loss: 1.072, reg_loss: 0.000), lr: 0.0003779860901118839\n",
      "step: 3000, acc: 0.656, loss: 1.036 (data_loss: 1.036, reg_loss: 0.000), lr: 0.0003709749220952664\n",
      "step: 3488, acc: 0.617, loss: 1.206 (data_loss: 1.206, reg_loss: 0.000), lr: 0.0003643783704999271\n",
      "training, acc: 0.643, loss: 1.138 (data_loss: 1.138, reg_loss: 0.000), lr: 0.0003643783704999271\n",
      "validation, acc: 0.692, loss: 0.962\n",
      "epoch: 6\n",
      "step: 0, acc: 0.664, loss: 0.998 (data_loss: 0.998, reg_loss: 0.000), lr: 0.0003643650938240116\n",
      "step: 500, acc: 0.594, loss: 1.309 (data_loss: 1.309, reg_loss: 0.000), lr: 0.0003578457684737878\n",
      "step: 1000, acc: 0.648, loss: 1.110 (data_loss: 1.110, reg_loss: 0.000), lr: 0.0003515556336790297\n",
      "step: 1500, acc: 0.688, loss: 1.078 (data_loss: 1.078, reg_loss: 0.000), lr: 0.0003454828122300916\n",
      "step: 2000, acc: 0.656, loss: 1.292 (data_loss: 1.292, reg_loss: 0.000), lr: 0.00033961623365596876\n",
      "step: 2500, acc: 0.641, loss: 1.060 (data_loss: 1.060, reg_loss: 0.000), lr: 0.00033394556687259974\n",
      "step: 3000, acc: 0.617, loss: 1.013 (data_loss: 1.013, reg_loss: 0.000), lr: 0.0003284611594678929\n",
      "step: 3488, acc: 0.467, loss: 1.243 (data_loss: 1.243, reg_loss: 0.000), lr: 0.00032327934568260433\n",
      "training, acc: 0.657, loss: 1.084 (data_loss: 1.084, reg_loss: 0.000), lr: 0.00032327934568260433\n",
      "validation, acc: 0.703, loss: 0.919\n",
      "epoch: 7\n",
      "step: 0, acc: 0.664, loss: 0.941 (data_loss: 0.941, reg_loss: 0.000), lr: 0.0003232688950669167\n",
      "step: 500, acc: 0.617, loss: 1.343 (data_loss: 1.343, reg_loss: 0.000), lr: 0.0003181268689953553\n",
      "step: 1000, acc: 0.648, loss: 1.072 (data_loss: 1.072, reg_loss: 0.000), lr: 0.00031314586334314526\n",
      "step: 1500, acc: 0.711, loss: 1.098 (data_loss: 1.098, reg_loss: 0.000), lr: 0.00030831843127582167\n",
      "step: 2000, acc: 0.641, loss: 1.190 (data_loss: 1.190, reg_loss: 0.000), lr: 0.00030363757818667637\n",
      "step: 2500, acc: 0.672, loss: 1.065 (data_loss: 1.065, reg_loss: 0.000), lr: 0.000299096727881797\n",
      "step: 3000, acc: 0.688, loss: 0.930 (data_loss: 0.930, reg_loss: 0.000), lr: 0.00029468969175458243\n",
      "step: 3488, acc: 0.567, loss: 1.088 (data_loss: 1.088, reg_loss: 0.000), lr: 0.00029051188193597116\n",
      "training, acc: 0.666, loss: 1.049 (data_loss: 1.049, reg_loss: 0.000), lr: 0.00029051188193597116\n",
      "validation, acc: 0.711, loss: 0.894\n",
      "epoch: 8\n",
      "step: 0, acc: 0.719, loss: 0.880 (data_loss: 0.880, reg_loss: 0.000), lr: 0.00029050344246579323\n",
      "step: 500, acc: 0.578, loss: 1.274 (data_loss: 1.274, reg_loss: 0.000), lr: 0.0002863442430489935\n",
      "step: 1000, acc: 0.664, loss: 1.019 (data_loss: 1.019, reg_loss: 0.000), lr: 0.00028230245885441666\n",
      "step: 1500, acc: 0.734, loss: 1.051 (data_loss: 1.051, reg_loss: 0.000), lr: 0.000278373187094619\n",
      "step: 2000, acc: 0.594, loss: 1.270 (data_loss: 1.270, reg_loss: 0.000), lr: 0.0002745517941959751\n",
      "step: 2500, acc: 0.648, loss: 0.985 (data_loss: 0.985, reg_loss: 0.000), lr: 0.00027083389757061993\n",
      "step: 3000, acc: 0.664, loss: 1.073 (data_loss: 1.073, reg_loss: 0.000), lr: 0.00026721534884963793\n",
      "step: 3488, acc: 0.517, loss: 1.149 (data_loss: 1.149, reg_loss: 0.000), lr: 0.00026377568515734216\n",
      "training, acc: 0.674, loss: 1.022 (data_loss: 1.022, reg_loss: 0.000), lr: 0.00026377568515734216\n",
      "validation, acc: 0.715, loss: 0.877\n",
      "epoch: 9\n",
      "step: 0, acc: 0.688, loss: 0.944 (data_loss: 0.944, reg_loss: 0.000), lr: 0.00026376872757965814\n",
      "step: 500, acc: 0.578, loss: 1.308 (data_loss: 1.308, reg_loss: 0.000), lr: 0.0002603353118817036\n",
      "step: 1000, acc: 0.641, loss: 1.035 (data_loss: 1.035, reg_loss: 0.000), lr: 0.00025699013157894735\n",
      "step: 1500, acc: 0.656, loss: 1.037 (data_loss: 1.037, reg_loss: 0.000), lr: 0.00025372982847863596\n",
      "step: 2000, acc: 0.664, loss: 1.102 (data_loss: 1.102, reg_loss: 0.000), lr: 0.00025055121266786927\n",
      "step: 2500, acc: 0.672, loss: 0.985 (data_loss: 0.985, reg_loss: 0.000), lr: 0.00024745125210333564\n",
      "step: 3000, acc: 0.703, loss: 0.947 (data_loss: 0.947, reg_loss: 0.000), lr: 0.0002444270629644114\n",
      "step: 3488, acc: 0.550, loss: 1.166 (data_loss: 1.166, reg_loss: 0.000), lr: 0.00024154589371980673\n",
      "training, acc: 0.679, loss: 0.999 (data_loss: 0.999, reg_loss: 0.000), lr: 0.00024154589371980673\n",
      "validation, acc: 0.720, loss: 0.858\n",
      "epoch: 10\n",
      "step: 0, acc: 0.695, loss: 0.895 (data_loss: 0.895, reg_loss: 0.000), lr: 0.0002415400594188546\n",
      "step: 500, acc: 0.633, loss: 1.271 (data_loss: 1.271, reg_loss: 0.000), lr: 0.00023865778859693084\n",
      "step: 1000, acc: 0.641, loss: 1.018 (data_loss: 1.018, reg_loss: 0.000), lr: 0.0002358434942572109\n",
      "step: 1500, acc: 0.719, loss: 1.017 (data_loss: 1.017, reg_loss: 0.000), lr: 0.00023309479965501968\n",
      "step: 2000, acc: 0.680, loss: 1.098 (data_loss: 1.098, reg_loss: 0.000), lr: 0.0002304094375705629\n",
      "step: 2500, acc: 0.633, loss: 0.948 (data_loss: 0.948, reg_loss: 0.000), lr: 0.000227785244071889\n",
      "step: 3000, acc: 0.672, loss: 0.915 (data_loss: 0.915, reg_loss: 0.000), lr: 0.00022522015269926351\n",
      "step: 3488, acc: 0.533, loss: 1.221 (data_loss: 1.221, reg_loss: 0.000), lr: 0.00022277172581255987\n",
      "training, acc: 0.685, loss: 0.980 (data_loss: 0.980, reg_loss: 0.000), lr: 0.00022277172581255987\n",
      "validation, acc: 0.724, loss: 0.844\n"
     ]
    }
   ],
   "source": [
    "nn_model_w_py.train(X_train, Y_train, \n",
    "                    validation_data=(X_test, Y_test), \n",
    "                    epochs=10,  \n",
    "                    batch_size=128,\n",
    "                    print_every=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <h3> Saving params (model needs to be initialized with same exact composition)\n",
    "- <h3> Saving whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PROPS_PATH = \"/Users/mikolajstarczewski/Desktop/Magisterka/NN_with_py/nn_with_py/NNModels/properties/\"\n",
    "\n",
    "nn_model_w_py.save_parameters(MODEL_PROPS_PATH + 'nn_model_w_py_params.parms')\n",
    "nn_model_w_py.save(MODEL_PROPS_PATH + 'nn_model_w_py_model.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = np.load(PATH + \"X_val.npy\")\n",
    "X_val = X_val.reshape(X_val.shape[0], -1)\n",
    "Y_val = np.load(PATH + \"Y_val.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(1, 2):\n",
    "    plt.title((Y_val[index]))\n",
    "    plt.imshow(X_val[index].reshape(32,32), cmap=cm.binary)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidences = nn_model_w_py.predict(X_val[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation, acc: 0.722, loss: 0.851\n"
     ]
    }
   ],
   "source": [
    "nn_model_w_py_v2 = Model()\n",
    "\n",
    "nn_model_w_py_v2.add(Layer_Dense(X_train.shape[1], 256))\n",
    "nn_model_w_py_v2.add(Activation_Relu())\n",
    "nn_model_w_py_v2.add(Layer_Dense(256, 128))\n",
    "nn_model_w_py_v2.add(Activation_Relu())\n",
    "nn_model_w_py_v2.add(Layer_Dense(128, 128))\n",
    "nn_model_w_py_v2.add(Activation_Relu())\n",
    "nn_model_w_py_v2.add(Layer_Dropout(0.2))\n",
    "nn_model_w_py_v2.add(Layer_Dense(128, 89))\n",
    "nn_model_w_py_v2.add(Activation_Softmax())\n",
    "\n",
    "nn_model_w_py_v2.set(\n",
    "    loss=Loss_CategoricalCrossentropy(),\n",
    "    accuracy=Accuracy_Categorical()\n",
    ")\n",
    "\n",
    "nn_model_w_py_v2.finalize()\n",
    "nn_model_w_py_v2.load_parameters(MODEL_PROPS_PATH + 'nn_model_w_py_params.parms')\n",
    "nn_model_w_py_v2.evaluate(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation, acc: 0.724, loss: 0.844\n"
     ]
    }
   ],
   "source": [
    "loaded_model = Model.load(MODEL_PROPS_PATH + 'nn_model_w_py_model.model')\n",
    "loaded_model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True value: 24\n",
      "Predicted: 24\n",
      "---------------\n",
      "True value: 77\n",
      "Predicted: 5\n",
      "---------------\n",
      "True value: 1\n",
      "Predicted: 1\n",
      "---------------\n",
      "True value: 83\n",
      "Predicted: 83\n",
      "---------------\n",
      "True value: 76\n",
      "Predicted: 67\n",
      "---------------\n",
      "True value: 6\n",
      "Predicted: 6\n",
      "---------------\n",
      "True value: 61\n",
      "Predicted: 61\n",
      "---------------\n",
      "True value: 27\n",
      "Predicted: 48\n",
      "---------------\n",
      "True value: 78\n",
      "Predicted: 71\n",
      "---------------\n",
      "True value: 86\n",
      "Predicted: 86\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    confidences = loaded_model.predict(X_val[i])\n",
    "    print(f\"True value: {Y_val[i]}\")\n",
    "    print(f\"Predicted: {np.argmax(confidences)}\")\n",
    "    print(\"---------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn-with-py-04WZxK0C-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
